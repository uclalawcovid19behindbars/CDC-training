---
title: "CDC Data Training #2"
author: "UCLA Law COVID-19 Behind Bars Data Project"
date: "April 2021"
output: 
  html_document:
    toc: true
    toc_float: true
---

## Introduction

We will cover a number of topics in this training around how to use the UCLA Law COVID-19 Behind Bars Data Project's data for analysis and visualization purposes. You can expect to leave with a better understanding of how to perform comparative analyses amongst carceral facilities along axes such as gender, public/private status, and state. We will also cover how to merge the UCLA data set with external datasets such as BJS, or Bureau of Justice Statistics, data. Finally, we will walk through how to create a county comparison using time series COVID-19 data from a prison and the county in which it is located.

There is no prior experience using the R programming language required for this training. For ease of use, we recommend opening this R Markdown file and following along within the RStudio application.

## Loading Packages

The code below loads in a few R packages that we'll use to manipulate the data in this session. A package bundles together code and documentation, and allows you to access helpful pre-written functions. To learn more about the most widely-used R packages, feel free to visit [this page](https://www.rstudio.com/products/rpackages/).

```{r package setup, message=FALSE, warning=FALSE}
## install packages by un-commenting the line below (only do this one time) 
# install.packages(c("tidyverse", "devtools", "skimr", "haven", "sjlabelled", "stringr))
## load packages into session
## do this every time you re-start R 
library(tidyverse) 
library(devtools)
library(skimr)
library(haven)
library(sjlabelled)
library(stringr)
```

The UCLA data team has been developing a custom R package called `behindbarstools` to help work with our data. You can read more about the package's functionality in the repository homepage [here](https://github.com/uclalawcovid19behindbars/behindbarstools). The package documentation is also available [here](https://rdrr.io/github/uclalawcovid19behindbars/behindbarstools/). 

```{r, message=FALSE, warning=FALSE}
## install UCLA package
devtools::install_github("uclalawcovid19behindbars/behindbarstools")
## load UCLA package into session
library(behindbarstools) 
## load the UCLA package documentation
help(package=behindbarstools) 
```

## Load Data

Our latest data presents a snapshot in time of cumulative infections, deaths, recoveries, and other variables across states and jurisdictions. To load in the latest facility-level data, run the code below. Note that we provide code to load the latest facility-level data using the `read_scrape_data` function in `behindbarstools`, along with code to load the data from the csv saved on Github in our [data repository](https://github.com/uclalawcovid19behindbars/data/tree/master/latest-data). 

Out Github repository also includes state-aggregated and nationally-aggregated counts available in separate data sheets. 

```{r, message=FALSE, warning=FALSE}
## load using behindbarstools 
latest_data <- read_scrape_data(all_dates = FALSE)
```

For several states, you can also access historical data for all of the state-run facilities for which we collect data. To read in the historical data for the state of California, for example, run the code below.

```{r, message=FALSE, warning=FALSE}
## load using behindbarstools 
ca_historical <- read_scrape_data(all_dates = TRUE, state = "California")
```

## Explore Data

I like using the `skim()` function to get a quick glance at any data. You can also view the variable names by calling the function `names()`. Before diving into exploring the data, we also strongly encourage you to reference the data dictionary that we host [here](https://github.com/uclalawcovid19behindbars/data). 

```{r, message=FALSE, warning=FALSE}
skim(latest_data)
names(latest_data)
```

To dig more into the variables, we can use functions like `table()` and `count()`. We use the pipe, `%>%`, to demonstrate a sequence of functions being called on the top-most data object. To read more about pipes, check out the [documentation here](https://magrittr.tidyverse.org/reference/pipe.html).

```{r, message=FALSE, warning=FALSE}
## what unique values exist for the variable "jurisdiction"?
table(latest_data$Jurisdiction)

## how many facilities were observed from each state on the most recent scrape?
latest_data %>% 
  count(State)

## add "arrange" to the sequence of pipes to view the counts in order
latest_data %>%
  count(State) %>%
  arrange(desc(n))
```


## Filter Data 

We have a lot of different types of facilities in our data set. To create a somewhat comparable group of facilities across the states, we filter to facilities that have had more than 25 COVID-19 infections among the incarcerated populations. 

We also want to filter out jails, since they function quite differently than prisons, and we only collect data from the handful of large jail systems in the US that report COVID-19 data on a regular basis. 

```{r, message=FALSE, warning=FALSE}
## number of observations
nrow(latest_data)

## note missing data 
table(is.na(latest_data$Residents.Confirmed))
table(is.na(latest_data$Residents.Population))

filtered_data <- latest_data %>%
  filter(Residents.Confirmed > 24) %>% # filter out prisons with less than 25 infections
  filter(Jurisdiction != "county") # filter out county jails 

nrow(filtered_data) # filtered out ~830 observations
```

Towards the goal of comparing facilities of different sizes, we calculate infection rates using the population from February 2020 as our denominator, and the cumulative number of COVID-19 infections among the incarcerated population as the numerator.

```{r, message=FALSE, warning=FALSE}
filtered_data <- filtered_data %>%
  mutate(confirmed_rate = Residents.Confirmed / Population.Feb20) 

## notice that some values are NA because of missing values in the denominator 
table(is.na(filtered_data$confirmed_rate)) 
table(is.na(filtered_data$Residents.Confirmed))
```

Which facilities had the highest infection rate on the most recent date of data collection? 

```{r, message=FALSE, warning=FALSE}
filtered_data %>%
  arrange(desc(confirmed_rate)) %>%
  select(Jurisdiction, State, Name, confirmed_rate) %>%
  head()
```

## Merge Data 
There is lots of helpful info contained within the BJS, or Bureau of Justice Statistics', [census data on correctional facilities](https://www.bjs.gov/index.cfm?ty=dcdetail&iid=255). We supply the BJS ID number for all facilities when it's identifiable. We can use the `BJS.ID` variable to merge our data with the BJS data set. 

```{r, message=FALSE, warning=FALSE}
table(is.na(filtered_data$BJS.ID)) ## BJS IDs present for about 2/3 of our data

## read in the BJS data
bjs_data_url <- "https://github.com/uclalawcovid19behindbars/CDC-training/raw/main/data/raw/37294-0001-Data.dta"

bjs_raw <- haven::read_dta(file = bjs_data_url)
names(bjs_raw)
```
It's hard to use this data when the variable names are so opaque! This data is *labelled*, meaning that the variable names and values are encoded in special ways. We use the `sjlabelled` and `haven` packages to make the BJS data more user-friendly. For more on working with labelled data in R, check out [this article](https://www.pipinghotdata.com/posts/2020-12-23-leveraging-labelled-data-in-r/).

```{r}
## convert column labels to column names
bjs <- sjlabelled::label_to_colnames(bjs_raw) %>%
  ## convert labelled variables to factors
  mutate_if(haven::is.labelled, haven::as_factor) 
skim(bjs)

## inspect the "private" operator variables more
table(bjs$`Facility operator`)
## what % of the facilities in the BJS data set are privately operated?
round((table(bjs$`Facility operator`) / nrow(bjs))*100, 2)

## merge the two data sets together
merged_df <- filtered_data %>% 
  ## UCLA variable named "BJS.ID" matches up to BJS variable "Facility ID #1" 
  left_join(bjs, 
            by = c("BJS.ID" = "Facility ID #1")) 

## view the merged data set
#View(merged_df)
```

## Disaggregate data by facility type

### Public/private status

Now, that we have merged the UCLA COVID-19 dataset with the BJS facility information dataset, we can create plots and analyses exploring facility-level infection rates by facility operator type. We utilize the BJS specification of facility operator to group facilities by private and non-private status.

```{r, message=FALSE, warning=FALSE}
## how many of the observations in the ucla data set are privately operated?
table(merged_df$`Facility operator`)

merged_out <- merged_df %>%
  ## rm observations with missing facility operator classification
  filter(!is.na(`Facility operator`)) %>% 
  ## create binary variable for is vs. private prisons 
  mutate(is_private = ifelse(`Facility operator` == "Private contractor",
                          TRUE,
                          FALSE))

## summarize by group
merged_out %>%
  group_by(is_private) %>%
  summarise(n = n(),
            mean_pop = mean(Population.Feb20, na.rm = TRUE),
            mean_cumulative_cases = mean(Residents.Confirmed, na.rm = TRUE), 
            mean_case_rate = mean(confirmed_rate, na.rm = TRUE),
            sum_deaths = sum_na_rm(Residents.Deaths))
```

Based on this information, we can create plots visualizing differences in confirmed infection rates based on whether the facility is privately contracted or not. 

```{r, message=FALSE, warning=FALSE}
# scatterplot of confirmed rate against population by private status
private_plot <- ggplot(merged_out, 
       aes(x = Population.Feb20, 
           y = confirmed_rate,
           color = is_private
           )) + 
    geom_point(size = 1.0) 
private_plot
```

Both the x-axis and the y-axis have most values grouped at the beginning of the scale, and a few outliers with very high populations and infection rates. Let's try putting the x- and y- axes on a log scale to bget a better look at what's going on in the data!

```{r, message=FALSE, warning=FALSE}
# log-transform 
private_plot + 
  scale_x_continuous(trans='log') +
  scale_y_continuous(trans='log') 
  
# boxplot of confirmed rates by private status 
ggplot(merged_out, 
       aes(x = is_private, 
           y = confirmed_rate, 
           color = is_private
           )) + 
    geom_boxplot() + 
  scale_y_continuous(trans='log')
```

### Gender

Next, we compare facilities infection rates and deaths along another axis: facility gender. Comparing the data UCLA collects from women's facilities to non-women's facilities (which includes men's and mixed gender facilities) helps show how the pandemic has impacted a particularly vulnerable group inside. 

```{r, message=FALSE, warning=FALSE}
## notice how few women's prisons there are 
table(filtered_data$Gender)

## combine "mens" and "mixed"
gender_dat <- filtered_data %>%
  mutate(gender_combined = ifelse(Gender == "Female",
                                  "Women",
                                  "Mixed")) %>%
  filter(!is.na(gender_combined)) ## rm observations with missing gender classification
  
## summarize by group
gender_dat %>%
  group_by(gender_combined) %>%
  summarise(n = n(),
            mean_pop = mean(Population.Feb20, na.rm = TRUE),
            mean_cumulative_cases = mean(Residents.Confirmed, na.rm = TRUE), 
            mean_case_rate = mean(confirmed_rate, na.rm = TRUE),
            sum_deaths = sum_na_rm(Residents.Deaths))
```

Let's create a plot comparing the infection rate and population by aggregate gender. 

```{r, message=FALSE, warning=FALSE}
## notice that women's prisons have smaller populations
gender_plot <- ggplot(gender_dat, 
       aes(x = Population.Feb20, 
           y = confirmed_rate,
           color = gender_combined)) + 
    geom_point(size = 1.0) 
gender_plot
```

```{r, message=FALSE, warning=FALSE}
gender_plot + 
  # Log transformation using scale_x/y_continuous()
  # ?scale_x_continuous to see built-in transformations
  scale_x_continuous(trans='log') +
  scale_y_continuous(trans='log') 

ggplot(gender_dat, 
       aes(x = gender_combined, 
           y = confirmed_rate, 
           color = gender_combined
           )) + 
    geom_boxplot() + 
  scale_y_continuous(trans='log') 
```

DISCUSS: What are your questions after looking at this plot? What questions, if any, does it answer?

## County-level Comparison

Next, we'll show how to use our historical COVID-19 data from carceral facilities to make comparisons between the infection rate inside of prison and in the surrounding county over time. We use the New York Times' COVID-19 data of cumulative cases and deaths in the US population on the county-level, available to the public [here](https://github.com/nytimes/covid-19-data).

```{r, message=FALSE, warning=FALSE}
## read in the NYT data
us_counties_df <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/" %>%
   # str_c("us.csv") %>% # uncomment this for overall US data
  str_c("us-counties.csv") %>%
  read_csv(col_types = cols()) %>%
  select(Date = date, 
         Confirmed = cases, 
         Deaths = deaths,
         State = state,
         County.FIPS = fips,
         County = county) %>%
  mutate(Name = "County Population")
```

We'll use the California historical data to compare the COVID-19 infection rates over time in the California Correctional Institution to the surrounding Kern County. 

```{r, message=FALSE, warning=FALSE}
## select a prison to focus on! 
## CALIFORNIA STATE PRISON CORCORAN had ~4 separate outbreaks, could use that one
focus_prison <- "CALIFORNIA CORRECTIONAL INSTITUTION"

## subset the data to the focus prison
ca_focus <- ca_historical %>%
  filter(Name == focus_prison) %>%
  ## rename historical population variable
  rename(Population = Residents.Population) %>%
  mutate(County.FIPS = as.character(County.FIPS),
         County.FIPS = stringr::str_pad(County.FIPS, 5, pad = "0")) %>%
  arrange(Date) %>%
  ## estimate active infections from cumulative count
  mutate(Active = diff_roll_sum(Residents.Confirmed, Date)) 
```
Now, we want to bind the county-level infection rate data with the UCLA prison data in order to make comparisons between COVID-19 outbreaks inside and outside of prison. To do so, we'll need to subset the county-level infection to the county in which our focus prison is located. We add in the total county population in order to calculate comparable rates, and then bind the two data sets together. 

```{r, message=FALSE, warning=FALSE}
## where is this prison located? 
ca_focus %>%
  select(County.FIPS, County) %>% 
  head(1)

prison_county_fips <- ca_focus$County.FIPS[1]

## subset NYT data to surrounding county
one_county <- us_counties_df %>% 
  filter(County.FIPS == prison_county_fips) %>%
  ## add total county population: https://www.census.gov/quickfacts/kerncountycalifornia
  mutate(Population = 900202) %>%
  arrange(Date) %>%
  ## estimate active infections from cumulative count
  mutate(Active = diff_roll_sum(Confirmed, Date)) 

county_comparison <- ca_focus %>%
  bind_rows(one_county) %>%
  ## calculate estimated active infection rate
  mutate(Percent = Active / Population)
```

Now that we have a comparable data set with both the focus prison and the surrounding county's estimated active infection rates, we can make a plot. 

```{r, message=FALSE, warning=FALSE, fig.width = 10}
county_comparison %>%
 ggplot(aes(x = Date, y = Percent, color = Name)) +
  geom_line(size = 1) +
  labs(title = "Comparison of CA Prison and Surrounding County with Active Infections", 
       y = "Percent of Population Actively Infected") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(legend.position = "top", 
        legend.title = element_blank())
```

## Data FAQs

#### How do I access the data if I'm not programming in R? 

If you're not programming in R, there are ways to access our data outside of calling the function `read_scrape_data()`. You can read the CSV files saved to our GitHub repositories from any computer. This works for both the most recently scraped data, and the historical data (for the states cleaned thus far). 

The latest data saved to our GitHub repository contains a subset of the descriptive facility variables included in the result of `read_scrape_data()`. Therefore, if you're interested in using variables such as `BJS.ID` or `Gender`, you may want to access the data from R using `read_scrape_data()`, and save the result as a CSV on your computer.

```{r, message=FALSE, warning=FALSE}
## load latest data from Github
latest_data <- read_csv(stringr::str_c(
  "https://raw.githubusercontent.com/uclalawcovid19behindbars/data/master/",
  "latest-data/adult_facility_covid_counts.csv")
)

## load historical data from Github 
## replace state acronym with the state you want to access
ca_historical <- read_csv(stringr::str_c(
  "https://raw.githubusercontent.com/uclalawcovid19behindbars/historical-data/main/data/",
  "CA-historical-data.csv") ## state acronym here
)
```

#### Why is it better to look at one facility/county rather than all of them simultaneously? 

When we compare the infection rates within a prison with the county in which it's located, we must contend with complexities within the data. For example, we know that correctional officers frequently do not live in the county where they work, and that when incarcerated people are released, they're often returning to counties other than the ones where they were incarcerated. While community spread analyses can reveal interesting trends between a prison and the surrounding area, we mention these complexities to caution against over-reliance on geographic denominators, particularly when our aggregating data away from the facility level. 

#### What limitations should be kept in mind when using this data?

We do our best to standardize variables across jurisdictions, but this is inherently challenging and constantly changing. We continue to add updates and known issues to our [data wiki](https://github.com/uclalawcovid19behindbars/data/wiki).

Each row in our data set represents an entity/date combination. In most cases, an entity is a facility, but some agencies only report aggregated data (e.g. state-wide). Additionally, we are only able to collect the data that agencies report. As a result, aggregating our data to estimate national or state-wide totals from facility-level data should be done with caution. 

Finally, our data is not comprehensive. We collect data for a small subset of all jails, and we continue to build additional scrapers as we discover additional COVID-19 carceral data sources. 

#### How can we calculate state-aggregated and nationally-aggregated counts? 

We maintain an up-to-date spreadsheet of [state-aggregated data](https://github.com/uclalawcovid19behindbars/data/blob/master/latest-data/state_aggregate_counts.csv) from state facilities, along with federal and immigration totals reported as separate rows. Data from county jails is NOT included in these aggregates because our data from county jails is not comprehensive. This dataset supplements information reported on agency websites with statewide aggregate totals reported by other sources including The Marshall Project and the AP.

We also maintain an up-to-date spreadsheet of [nationally-aggregated data](https://github.com/uclalawcovid19behindbars/data/blob/master/latest-data/national_aggregate_counts.csv) from state, federal, and immigration facilities based on the same set of sources as the state-aggregated file. This dataset also reports the number of agencies reporting each metric and lists the agencies that are missing from each aggregated metric.

#### What is unique about the UCLA data? 

This is the only dataset that contains facility-level data for COVID-19 infections, deaths, and testing for all state and federal systems. We created this dataset by building and maintaining over 100 web scrapers to collect data 3-4 times per week, cleaning and standardizing the data on a daily basis, and loading the dataset to publicly-available platforms. The unique opportunities offered by this dataset include the ability to look at COVID-19-related trends at specific facilities as well as make comparisons among facilities and between facilities and surrounding counties." 